FULL_HOSTNAME=x4404c0s0b0n0.hostmgmt.cm.aurora.alcf.anl.gov
Setting up for Aurora run
Setting hardware affinities
Setting up for Intel GPUS
Location of dragon:
/lus/flare/projects/hpe_dragon_collab/balin/PASC25/_dragon_env/bin/dragon
Running on 3 nodes
Reading files from /flare/datascience/dragon/tiny
Running with 104 max. processes in Pool per Node
Mem per node 256
Managers 1
/opt/aurora/24.347.0/support/tools/pti-gpu/0.11.0/lib64:/opt/cray/pals/1.4/lib:/opt/cray/libfabric/1.22.0/lib64:/opt/cray/libfabric/1.22.0/lib:/opt/aurora/24.347.0/spack/unified/0.9.2/install/linux-sles15-x86_64/oneapi-2025.0.5/mpich-develop-git.6037a7a-sxnhr7p/lib:/opt/aurora/24.347.0/spack/unified/0.9.2/install/linux-sles15-x86_64/oneapi-2025.0.5/yaksa-0.3-7ks5f26/lib:/opt/aurora/24.347.0/spack/unified/0.9.2/install/linux-sles15-x86_64/oneapi-2025.0.5/hwloc-2.11.3-mpich-g7c7dzn/lib:/opt/aurora/24.347.0/spack/unified/0.9.2/install/linux-sles15-x86_64/gcc-13.3.0/libxml2-2.13.5-jxhkqdj/lib:/opt/aurora/24.347.0/spack/unified/0.9.2/install/linux-sles15-x86_64/gcc-13.3.0/libiconv-1.17-jjpb4sl/lib:/opt/aurora/24.347.0/support/libraries/khronos/default/lib64:/opt/aurora/24.347.0/oneapi/pti/latest/lib:/opt/aurora/24.347.0/oneapi/tcm/latest/lib:/opt/aurora/24.347.0/oneapi/umf/latest/lib:/opt/aurora/24.347.0/oneapi/ipp/latest/lib:/opt/aurora/24.347.0/oneapi/ippcp/latest/lib:/opt/aurora/24.347.0/oneapi/debugger/latest/opt/debugger/lib:/opt/aurora/24.347.0/oneapi/ccl/latest/lib:/opt/aurora/24.347.0/oneapi/dal/latest/lib:/opt/aurora/24.347.0/oneapi/dnnl/latest/lib:/opt/aurora/24.347.0/oneapi/tbb/latest/lib/intel64/gcc4.8:/opt/aurora/24.347.0/oneapi/mkl/latest/lib:/opt/aurora/24.347.0/oneapi/compiler/latest/opt/compiler/lib:/opt/aurora/24.347.0/oneapi/compiler/latest/lib:/opt/aurora/24.347.0/spack/unified/0.9.2/install/linux-sles15-x86_64/gcc-13.3.0/gcc-13.3.0-4enwbrb/lib64:/opt/aurora/24.347.0/spack/unified/0.9.2/install/linux-sles15-x86_64/gcc-13.3.0/gcc-13.3.0-4enwbrb/lib:/opt/aurora/24.347.0/spack/unified/0.9.2/install/linux-sles15-x86_64/gcc-13.3.0/mpc-1.3.1-rdrlvsl/lib:/opt/aurora/24.347.0/spack/unified/0.9.2/install/linux-sles15-x86_64/gcc-13.3.0/mpfr-4.2.1-gkcdl5w/lib:/opt/aurora/24.347.0/spack/unified/0.9.2/install/linux-sles15-x86_64/gcc-13.3.0/gmp-6.3.0-mtokfaw/lib:/opt/aurora/24.347.0/spack/unified/0.9.2/install/linux-sles15-x86_64/gcc-13.3.0/gcc-runtime-13.3.0-ghotoln/lib
dragon /flare/hpe_dragon_collab/balin/PASC25/MLDocking_Dragon/Dragon//dragon_driver_sequential.py --managers_per_node=1 --data_path=/flare/datascience/dragon/tiny --max_procs_per_node=104 --mem_per_node=256 --inference_node_num=2 --sorting_node_num=2 --simulation_node_num=1

Begun dragon driver
Reading inference data from path: /flare/datascience/dragon/tiny
Running on 3 total nodes

Component inference running on [4121026370672822532, 8248015025938574390] nodes
Component sorting running on [4121026370672822532, 8248015025938574390] nodes
Component simulation running on [7536063773007423720] nodes
Component training running on [7536063773007423720] nodes
Estimating dictionary sizes with a maximum data pool utiliztion of 50.0 per cent
Memory available for ddicts: 1701 GB
Setting data_dict size to 2 GB
Setting sim_dict size to 1 GB
Setting model_list_dict size to 3 GB
Launched Dragon Dictionary for inference with total memory size 2147483648 on 2 nodes
Launched Dragon Dictionary for docking simulation with total memory size 1073741824 on 1 nodes
Launched Dragon Dictionary for model list with total memory size 3221225472 on 3 nodes
Loading inference data into Dragon Dictionary ...
Number of files to read is 24
Number of Pool processes is 24
Total data read in 0.14365918654948473 GB
Loaded inference data in 7.792 seconds
model weights: num_layers=14 num_weights=28 tot_memory=32015236
Saved model to dictionary
Loaded pretrained model
Finished workflow setup in 15.806 seconds
*** Start loop iter 0 ***
Current checkpoint: 0
Launching inference with 24 processes ...
datetime launch inference mp.Process 22:56:05.734
datetime start inference mp.Process 22:56:11.191
Starting Process Group for Inference
datetime start inference ProcessGroup 22:56:11.194
datetime start infer 3 22:56:16.558
datetime start infer 5 22:56:16.558
datetime start infer 1 22:56:16.697
datetime start infer 2 22:56:16.703
datetime start infer 14 22:56:16.947
datetime start infer 11 22:56:17.503
datetime start infer 15 22:56:17.503
datetime start infer 6 22:56:17.505
datetime start infer 7 22:56:17.630
datetime start infer 10 22:56:17.630
datetime start infer 8 22:56:17.639
datetime start infer 9 22:56:17.642
datetime start infer 4 22:56:17.672
datetime start infer 0 22:56:17.673
datetime start infer 19 22:56:18.191
datetime start infer 18 22:56:18.249
datetime start infer 20 22:56:18.270
datetime start infer 21 22:56:18.273
datetime start infer 22 22:56:18.310
datetime start infer 23 22:56:18.316
datetime start infer 16 22:56:18.320
datetime start infer 12 22:56:18.321
datetime start infer 13 22:56:18.321
datetime start infer 17 22:56:18.324
datetime finish infer 5 22:56:18.474
datetime finish infer 2 22:56:18.652
datetime finish infer 8 22:56:19.750
datetime finish infer 11 22:56:19.879
datetime finish infer 12 22:56:20.232
datetime finish infer 17 22:56:20.747
datetime finish infer 22 22:56:20.929
datetime finish infer 20 22:56:23.501
datetime finish infer 18 22:56:23.844
datetime finish infer 10 22:56:25.781
datetime finish infer 3 22:56:40.534
datetime finish infer 0 22:56:41.648
datetime finish infer 4 22:56:41.765
datetime finish infer 23 22:56:42.188
datetime finish infer 1 22:56:42.595
datetime finish infer 21 22:56:42.705
datetime finish infer 13 22:56:42.842
datetime finish infer 14 22:56:42.972
datetime finish infer 15 22:56:43.130
datetime finish infer 19 22:56:43.185
datetime finish infer 9 22:56:43.189
datetime finish infer 6 22:56:43.382
datetime finish infer 7 22:56:43.413
datetime finish infer 16 22:56:43.757
Joined Process Group for Inference
datetime closed inference ProcessGroup 22:56:45.045
Performed inference in 40.355 seconds 

